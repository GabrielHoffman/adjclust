<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Notes on CHAC implementation in adjclust â€¢ adjclust</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">adjclust</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/hicClust.html">Clustering of Hi-C contact maps</a>
    </li>
    <li>
      <a href="../articles/notesCHAC.html">Notes on CHAC implementation in adjclust</a>
    </li>
    <li>
      <a href="../articles/snpClust.html">Inferring Linkage Disequilibrium blocks from genotypes</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/pneuvial/adjclust">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Notes on CHAC implementation in adjclust</h1>
                        <h4 class="author">Pierre Neuvial, Nathalie Villa-Vialaneix</h4>
            
            <h4 class="date">2017-12-13</h4>
          </div>

    
    
<div class="contents">
<p>This document has two parts:</p>
<ul>
<li><p>the first part aims at clarifying relations between dissimilarity and similarity methods for hierarchical agglomerative clustering (HAC) and at explaining implementation choices in <code>adjclust</code>;</p></li>
<li><p>the second part describes the different types of dendrograms that are implemented in <code>plot.chac</code>.</p></li>
</ul>
<p>In this document, we suppose given <span class="math inline">\(n\)</span> objects, <span class="math inline">\(\{1, \ldots, n\}\)</span> that have to be clustered using adjacency-constrained HAC, that is, in such a way that only adjacent objects/clusters can be merged.</p>
<div id="notes-on-relations-between-similarity-and-dissimilarity-implementation" class="section level1">
<h1 class="hasAnchor">
<a href="#notes-on-relations-between-similarity-and-dissimilarity-implementation" class="anchor"></a>Notes on relations between similarity and dissimilarity implementation</h1>
<div id="basic-implementation-of-chac-in-adjclust" class="section level2">
<h2 class="hasAnchor">
<a href="#basic-implementation-of-chac-in-adjclust" class="anchor"></a>Basic implementation of CHAC in <code>adjclust</code>
</h2>
<p>The basic implementation of <code>adjclust</code> takes, as an input, a kernel <span class="math inline">\(k\)</span> which is supposed to be symmetric and positive (in the kernel sense) and to satisfy: <span class="math display">\[
    k(i,i) = 1,\qquad \forall\, i=1,\ldots,n.
\]</span></p>
<p>If your data are under this format, then the constrained clustering can be performed with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjClust.html">adjClust</a></span>(k, <span class="dt">type =</span> <span class="st">"similarity"</span>)</code></pre></div>
<p>or with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjClust.html">adjClust</a></span>(k, <span class="dt">type =</span> <span class="st">"similarity"</span>, <span class="dt">h =</span> h)</code></pre></div>
<p>if, in addition, the kernel <span class="math inline">\(k\)</span> is supposed to have only null entries outside of a diagonal of size <code>h</code>.</p>
<p>The implementation is the one described in [1].</p>
</div>
<div id="more-advanced-used-for-kernel-or-similarity-matrices" class="section level2">
<h2 class="hasAnchor">
<a href="#more-advanced-used-for-kernel-or-similarity-matrices" class="anchor"></a>More advanced used for kernel or similarity matrices</h2>
<div id="non-positive-but-normalized-similarities" class="section level3">
<h3 class="hasAnchor">
<a href="#non-positive-but-normalized-similarities" class="anchor"></a>Non positive but normalized similarities</h3>
<p>In this section, the available data set is a matrix <span class="math inline">\(s\)</span> that can either have only positive entries (in this case it is called a similarity) or both positive and non-positive entries. If, in addition, <span class="math inline">\(s(i,i) = 1\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span> and <span class="math inline">\(s(i,j) \leq 1\)</span> for all <span class="math inline">\(i,j=1,\ldots,n\)</span> then the algorithm implemented in <code>adjclust</code> can be applied directly, similarly as for a standard kernel (section 1). This section explains why this is the case.</p>
<p>The interpretation is similar to the kernel case, under the assumption that small similarity values or similarity values that are strongly negative are less expected to be clustered together than large similarity values. The application of the method is justified by the fact that, for a given matrix <span class="math inline">\(s\)</span> described as above, we can find a <span class="math inline">\(\lambda &gt; 0\)</span> such that the matrix <span class="math inline">\(k_\lambda\)</span> defined by <span class="math display">\[
  \forall\,1,\ldots,n,\qquad k_\lambda(i,j) = s(i,j) + \lambda 
  \mathbb{1}_{\{i=j\}}
\]</span> is a kernel (<em>i.e.</em>, the matrix <span class="math inline">\(k = s + \lambda I\)</span> is positive definite; indeed, it is the case for any <span class="math inline">\(\lambda\)</span> larger than the opposite of the smallest negative eigenvalue of <span class="math inline">\(s\)</span>. [3] shows that the HAC obtained from the distance induced by the kernel <span class="math inline">\(k_\lambda\)</span> in its feature space and the HAC obtained from the <em>ad hoc</em> dissimilarity defined by <span class="math display">\[
  \forall\, i,j=1,\ldots,n,\qquad d(i,j) = \sqrt{s(i,i) + s(j,j) - 2s(i,j)} = 
  \sqrt{2(1-s(i,j))}
\]</span> are identical, except that all the merging levels are shifted by <span class="math inline">\(\lambda\)</span>.</p>
<p>In conclusion, to address this case, the command lines that have to be used are the ones described in section 1.</p>
</div>
<div id="non-normalized-similarities" class="section level3">
<h3 class="hasAnchor">
<a href="#non-normalized-similarities" class="anchor"></a>Non normalized similarities</h3>
<p>Suppose now that the data set is described by a matrix <span class="math inline">\(s\)</span> as in the previous section except that which does not satisfy one of the two following conditions:</p>
<ul>
<li>[C1] <span class="math inline">\(\forall i \in\{1,\ldots,n\}\)</span>, <span class="math inline">\(s(i,i)=1\)</span>
</li>
<li>[C2] <span class="math inline">\(\forall i,j \in\{1,\ldots,n\}\)</span>, <span class="math display">\[
  2s(i,j) \leq s(i,i) + s(j,j).
\]</span>
</li>
</ul>
<p>These properties were implicitly assumed to hold in the original implementation of constrained HAC described in [1]. Specifically, this implementation relied on the implicit dissimilarity <span class="math display">\[
  \forall\,i,j=1,\ldots,n,\qquad d^2(i,j) = s(i,i) + s(j,j) - 2s(i,j)
\]</span> which has no meaning if 2. above does not hold. If either [C1] or [C2] is not met, the package performs the following pre-transformations:</p>
<ol style="list-style-type: decimal">
<li><p>a matrix <span class="math inline">\(s^{*}\)</span> is defined as <span class="math display">\[
  \forall\,i,j=1,\ldots,n,\qquad s^{*}(i,j) = s(i,j) + \lambda 
  \mathbb{1}_{\{i=j\}}
\]</span> for a <span class="math inline">\(\lambda\)</span> large enough to ensure that [C2] holds for <span class="math inline">\(s^{*}\)</span>. In the package, <span class="math inline">\(\lambda\)</span> is chosen as <span class="math display">\[
  \lambda := \epsilon + \max_{i,j} \left(s(i,j) - s(i,i)\right)_+
\]</span> for a small <span class="math inline">\(\epsilon &gt; 0\)</span>. This case is justified by the property described in Section 2.1 (Non-positive but normalized similarities). The underlying idea is that, shifting the diagonal entries of a similarity matrix does not change HAC result and thus they can be shifted until they induce a proper <em>ad-hoc</em> dissimilarity matrix;</p></li>
<li><p><span class="math inline">\(s^{*}\)</span> is then normalized to unit diagonal ([C1]), in order to allow its use in the original implementation as in [1]: <span class="math display">\[
  \forall\,i,j=1,\ldots,n,\qquad s^{**} =s^{*}(i,j) + 1 - 
  \frac{1}{2} (s^{*}(i,i) +s^{*}(j,j)).
\]</span></p></li>
</ol>
<p>By definition, <span class="math inline">\(s^{**}\)</span> satisfies [C1] and [C2], and the <em>ad-hoc</em> dissimilarities induced by <span class="math inline">\(s^{*}\)</span> and <span class="math inline">\(s^{**}\)</span> are identical: <span class="math display">\[
  \forall\,i=1,\ldots,j,\qquad d^{**}(i,j) = d^{*}(i,j).
\]</span></p>
<p><strong>Important remark</strong>: The transformation described above affects all the elements of the similarity matrix (and not only its diagonal), contrarily to what happens in section 2.1. Hence, it is not (yet) compatible with the fast implementation that requires to have a <span class="math inline">\(h\)</span>-band centered on the diagonal outside of which all entries are supposed to be 0. The current behavior of the package consists in forbidding the use of the fast implementation when the provided matrix is not normalized (all diagonal entries equal to 1). For all other cases, the constrained clustering from <span class="math inline">\(s\)</span>, including the above-described matrix transformations, is available with the full matrix, i.e.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjClust.html">adjClust</a></span>(s, <span class="dt">type =</span> <span class="st">"similarity"</span>)</code></pre></div>
</div>
<div id="case-of-dissimilarity-data" class="section level3">
<h3 class="hasAnchor">
<a href="#case-of-dissimilarity-data" class="anchor"></a>Case of dissimilarity data</h3>
<p>The original implementation of (unconstrained) HAC in <code><a href="http://www.rdocumentation.org/packages/stats/topics/hclust">stats::hclust</a></code> takes as input a dissimilarity matrix. However, the implementation of <code>adjclust</code> is based on a kernel/similarity approach. We describe in this section how the case of dissimilarity is handled.</p>
<p>Suppose given a dissimilarity <span class="math inline">\(d\)</span> which satisfies:</p>
<ul>
<li><p><span class="math inline">\(d\)</span> has non negative entries: <span class="math inline">\(d(i,j) \geq 0\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span>;</p></li>
<li><p><span class="math inline">\(d\)</span> is symmetric: <span class="math inline">\(d(i,j) = d(j,i)\)</span> for all <span class="math inline">\(i,j=1,\ldots,n\)</span>;</p></li>
<li><p><span class="math inline">\(d\)</span> has a null diagonal: <span class="math inline">\(d(i,i) = 0\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span>.</p></li>
</ul>
<p>Any sequence of positive numbers <span class="math inline">\((a_i)_{i=1,\ldots,n}\)</span> would provide a similarity <span class="math inline">\(s\)</span> for which <span class="math inline">\(d\)</span> is the <em>ad-hoc</em> dissimilarity by setting: <span class="math display">\[
  \left\{ \begin{array}{l}
    s(i,i) = a_i\\
    s(i,j) = \frac{1}{2} (a_i + a_j - d^2(i,j))
  \end{array} \right. .
\]</span> By definition, such an <span class="math inline">\(s\)</span> satisfies [C2], and any choice for <span class="math inline">\((a_i)_{i=1,\ldots,n}\)</span> yields the same clustering (since they all correspond to the same <em>ad-hoc</em> dissimilarity). To satisfy [C1], the choice <span class="math inline">\(a_i = 1\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span> has been made.</p>
<p>The similarity <span class="math inline">\(s\)</span> is thus processed as described in the previous sections. In short, since by definition it satisfies [C1] and [C2] it is processed as described in Sections 1 or 2.1 and the basic and the sparse implementations are both available with, respectively,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjClust.html">adjClust</a></span>(d, <span class="dt">type =</span> <span class="st">"dissimilarity"</span>)</code></pre></div>
<p>and</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjClust.html">adjClust</a></span>(d, <span class="dt">type =</span> <span class="st">"dissimilarity"</span>, <span class="dt">h =</span> h)</code></pre></div>
</div>
</div>
</div>
<div id="options-for-displaying-the-dendrogram" class="section level1">
<h1 class="hasAnchor">
<a href="#options-for-displaying-the-dendrogram" class="anchor"></a>Options for displaying the dendrogram</h1>
<p>In this section, we suppose given an Euclidean distance <span class="math inline">\(d\)</span> between objects (even though the results described in this section are not specific to this case, they are described more easily using this framework). Wardâ€™s criterion, that is implemented in <code>adjclust</code> aims at minimizing the Error Sum of Squares (ESS) which is equal to: <span class="math display">\[
  \mbox{ESS}(\mathcal{C}) = \sum_{C \in \mathcal{C}} \sum_{i \in C} d^2(i, g_C)
\]</span> where <span class="math inline">\(\mathcal{C}\)</span> is the clustering and <span class="math inline">\(g_C = \frac{1}{\mu_C} \sum_{i \in C} i\)</span> is the center of gravity of the cluster <span class="math inline">\(C\)</span> with <span class="math inline">\(\mu_C\)</span> elements [5]. In the sequel, we will denote:</p>
<ul>
<li><p><em>within-cluster dispersion</em> which, for a given cluster <span class="math inline">\(C\)</span>, is equal to <span class="math display">\[
  I(C) = \sum_{i \in C} d^2(i, g_C).
\]</span> We can prove that <span class="math inline">\(I(C) = \frac{1}{2\mu_C} \sum_{i,j \in C} d^2(i,j)\)</span> (see [4] for instance);</p></li>
<li><p><em>average within-cluster dispersion</em> which is equal to <span class="math inline">\(\frac{I(C)}{\mu_C}\)</span> and corresponds to the cluster variance.</p></li>
</ul>
<p>Usually, the results of standard HAC are displayed under the form of a dendrogram for which the heights of the different merges correspond to the linkage criterion <span class="math display">\[
  \delta(A,B) = I(A \cup B) - I(A) - I(B)
\]</span> of that merge. This criterion corresponds to the increase in total dispersion (ESS) that occurs by merging the two clusters <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. However, for constrained HAC, there is no guaranty that this criterion is non decreasing (see [2] for instance) and thus, the dendrogram build using this method can contain reversals in its branches. This is the default option in <code>plot.chac</code> (that corresponds to <code>mode = "standard"</code>). To provide dendrograms that are easier to interpret, alternative options have been implemented in the package: the first one is a simple correction of the standard method, and the three others are suggested by [3].</p>
<p>In the sequel, we denote by <span class="math inline">\((m_t)_{t=1,\ldots,n-1}\)</span> the series of linkage criterion values obtained during the clustering.</p>
<div id="mode-corrected" class="section level2">
<h2 class="hasAnchor">
<a href="#mode-corrected" class="anchor"></a><code>mode = "corrected"</code>
</h2>
<p>This option simply corrects the heights by adding the minimal value making them non decreasing. More precisely, if at a given step <span class="math inline">\(t \in \{2,\ldots,n-1\}\)</span> of the clustering, we have that <span class="math inline">\(m_t &lt; m_{t-1}\)</span> then, we define the corrected weights as: <span class="math display">\[
  \tilde{m}_{t'} = \left\{ \begin{array}{ll}
    m_{t'} &amp; \textrm{if } t' &lt; t\\
    m_{t'} + (m_{t-1} - m_t) &amp; \textrm{otherwise}
  \end{array} \right..
\]</span> This correction is iteratively performed for all decreasing merges, ensuring a visually increasing dendrogram.</p>
</div>
<div id="mode-total-disp" class="section level2">
<h2 class="hasAnchor">
<a href="#mode-total-disp" class="anchor"></a><code>mode = "total-disp"</code>
</h2>
<p>This option represents the dendrogram using the total dispersion (that is the objective function) at every level of the clustering. It can easily be proved that the total dispersion is equal to ESS<span class="math inline">\(_t = \sum_{t' \leq t} m_{t'}\)</span> and that this quantity is always non decreasing. This is the quantity recommanded by [2] to display the dendrogram.</p>
</div>
<div id="mode-within-disp" class="section level2">
<h2 class="hasAnchor">
<a href="#mode-within-disp" class="anchor"></a><code>mode = "within-disp"</code>
</h2>
<p>This option represents a cluster specific criterion by using the within cluster dispersion of the two clusters being merged at every given step of the algorithm. It can be proved that this quantity is also non decreasing but it is also very dependant of the cluster size, leading to flattened dendrogram in most cases.</p>
</div>
<div id="mode-average-disp" class="section level2">
<h2 class="hasAnchor">
<a href="#mode-average-disp" class="anchor"></a><code>mode = "average-disp"</code>
</h2>
<p>This last option addresses the problem of the dependency to cluster sizes posed by the previous method (<code>"within-disp"</code>) by using the average within-cluster dispersion of the two clusters being merged at avery given step of the algorithm. This criterion is also a cluster specific one but does not guaranty the absence of reversals in heights.</p>
</div>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<p>[1] Dehman A. (2015). <a href="https://tel.archives-ouvertes.fr/tel-01288568/">Spatial clustering of linkage disequilibrium blocks for genome-wide association studies</a>. Phd Thesis, UniversitÃ© Paris Saclay.</p>
<p>[2] Grimm, E.C. (1987) CONISS: a fortran 77 program for stratigraphically constrained cluster analysis by the method of incremental sum of squares. <em>Computers &amp; Geosciences</em>, <strong>13</strong>(1), 13-35.</p>
<p>[3] Miyamoto S., Abe R., Endo Y., Takeshita J. (2015) Ward method of hierarchical clustering for non-Eclidean similarity measures. In: <em>Proceedings of the VIIth International Conference of Soft Computing and Pattern Recognition</em> (SoCPaR 2015).</p>
<p>[4] Murtagh, F. and Legendre, P. (2014) Wardâ€™s hierarchical agglomerative clustering method: which algorithms implement Wardâ€™s criterion? <em>Journal of Classification</em>, <strong>31</strong>, 274-295.</p>
<p>[5] Ward, J.H. (1963) Hierarchical grouping to optimize an objective function. <em>Journal of the American Statistical Association</em>, <strong>58</strong>(301), 236-244.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#notes-on-relations-between-similarity-and-dissimilarity-implementation">Notes on relations between similarity and dissimilarity implementation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#basic-implementation-of-chac-in-adjclust">Basic implementation of CHAC in <code>adjclust</code></a></li>
      <li><a href="#more-advanced-used-for-kernel-or-similarity-matrices">More advanced used for kernel or similarity matrices</a></li>
      </ul>
</li>
      <li>
<a href="#options-for-displaying-the-dendrogram">Options for displaying the dendrogram</a><ul class="nav nav-pills nav-stacked">
<li><a href="#mode-corrected"><code>mode = "corrected"</code></a></li>
      <li><a href="#mode-total-disp"><code>mode = "total-disp"</code></a></li>
      <li><a href="#mode-within-disp"><code>mode = "within-disp"</code></a></li>
      <li><a href="#mode-average-disp"><code>mode = "average-disp"</code></a></li>
      </ul>
</li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="http://www.math-evry.cnrs.fr/members/cambroise/">Christophe Ambroise</a>, Shubham Chaturvedi, Alia Dehman, Michel Koskas, <a href="https://www.math.univ-toulouse.fr/~pneuvial/">Pierre Neuvial</a>, Guillem Rigaill, <a href="http://nathalievilla.org">Nathalie Villa-Vialaneix</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
